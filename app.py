import os
os.environ["STREAMLIT_SERVER_FILE_WATCHER_TYPE"] = "none"

import streamlit as st
import nest_asyncio
import pandas as pd
import datetime
from pathlib import Path
from zoneinfo import ZoneInfo
from io import BytesIO
import zipfile
import json

from new import run_pipeline, make_html_from_csv, run_pipeline_cached, make_html_string_from_csv

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
now_kst = datetime.datetime.now(ZoneInfo("Asia/Seoul"))

# ì´ë²¤íŠ¸ ë£¨í”„ ì¶©ëŒ ë°©ì§€ (async ì‚¬ìš© ì‹œ í•„ìˆ˜)
nest_asyncio.apply()


st.set_page_config(page_title="OpenAlex Paper Metadata Pipeline", layout="wide")


# ìºì‹œ ë°ì½”ë ˆì´í„° ì œê±° (íŒŒì¼ ìƒì„±/ì™¸ë¶€ I/OëŠ” ìºì‹œ ë¹„ê¶Œì¥)
def cached_run(issns, year_start, year_end, email,
               progress_bar=None, progress_text=None):

    # storage í•˜ìœ„ì— ê²°ê³¼ ì €ì¥
    final_csv_path, _ = run_pipeline_cached(
        issns=issns, year_start=year_start, year_end=year_end, email=email,
        include_only_with_abstract=False, make_html=True,
        base_dir=Path("storage")
    )

    if progress_bar:
        progress_bar.progress(0.7)
    if progress_text:
        progress_text.info("ìµœì¢… CSV ìƒì„± ë° í™•ì¸ ì¤‘ ..")

    #ìµœì¢… CSV ê²½ë¡œ ë¬¸ìì—´ -> Path ê°ì²´
    out_path = Path(final_csv_path)

    final_html = make_html_from_csv(str(out_path))

    if progress_bar:
        progress_bar.progress(1.0)
    if progress_text:
        progress_text.success("ëª¨ë“  êµ¬ê°„ ì²˜ë¦¬ ë° ìµœì¢… íŒŒì¼ ìƒì„± ì™„ë£Œ")

    st.sidebar.caption(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ Â· {now_kst:%H:%M:%S}")

    return str(out_path), final_html

def sidebar_controls():
    st.sidebar.header("ì„¤ì •")
    issns_text = st.sidebar.text_area(
        "ISSN ë¦¬ìŠ¤íŠ¸ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)",
        value="0043-1354\n0011-9164\n0733-9429",
        height=100,
    )
    issns = [s.strip() for s in issns_text.splitlines() if s.strip()]

    year_col1, year_col2 = st.sidebar.columns(2)
    year_start = year_col1.number_input("ì‹œì‘ ì—°ë„", value=2015, step=1)
    year_end = year_col2.number_input("ì¢…ë£Œ ì—°ë„", value=2024, step=1)

    email = st.sidebar.text_input("OpenAlex ì´ë©”ì¼", value="s0124kw@gmail.com")
    run_btn = st.sidebar.button("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰", width="stretch")
    return issns, int(year_start), int(year_end), email, run_btn

def app():
    st.title("Paper Metadata Collection Pipeline")

    if "runs" not in st.session_state:
        st.session_state.runs = []

    issns, year_start, year_end, email, run_btn = sidebar_controls()

    # ì§„í–‰ë¥ /ë©”ì‹œì§€ ìŠ¬ë¡¯ -> ì§„í–‰ì¤‘ì¸ ìƒí™© ì¶œë ¥
    progress_bar = st.progress(0, text="ëŒ€ê¸° ì¤‘")
    progress_text = st.empty()

    # ë¯¸ë¦¬ë³´ê¸° í–‰ ìˆ˜(ê³ ì •)
    PREVIEW_N = 1000
    # CSV ë‹¤ìš´ë¡œë“œ ì„ê³„ê°’(MB)
    THRESHOLD_MB = 150

    if run_btn:

        # ì‹¤í–‰ ì‹œê°„ ê¸°ë¡
        start_time = datetime.datetime.now(ZoneInfo("Asia/Seoul"))

        with st.spinner("íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆì–´ìš”)"):
            progress_text.info("ì¤€ë¹„ ì¤‘..")
            final_csv, final_html = cached_run(issns, year_start, year_end, email,
                                               progress_bar=progress_bar, progress_text=progress_text
                                               )
        
        # ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
        end_time = datetime.datetime.now(ZoneInfo("Asia/Seoul"))
        duration = end_time - start_time
        
        # ì„¸ì…˜ ì´ë ¥ì— ê¸°ë¡ (ë¼ë²¨: issn|ì—°ë„|ì‹œê°)
        prefix = Path(final_csv).stem.replace(f"_{year_start}_{year_end}_ror_extract_name", "")

        label = f"{prefix} | {year_start}-{year_end} | {start_time.strftime('%m/%d %H:%M')}"
        st.session_state.runs.append({"label": label, "csv": final_csv, "html": final_html,
                                      "start": start_time.strftime('%Y-%m-%d %H:%M:%S'),
                                      "end": end_time.strftime('%Y-%m-%d %H:%M:%S'),
                                      "duration": str(duration)
                                      })

        # âœ… ì´ë ¥ ë“œë¡­ë‹¤ìš´(ê¸°ë³¸ê°’=ë°©ê¸ˆ ì‹¤í–‰í•œ í•­ëª©)
        options = [r["label"] for r in st.session_state.runs]
        selected = st.selectbox("ì‹¤í–‰ ê²°ê³¼ ì„ íƒ", options, index=len(options)-1)
        sel = next(r for r in st.session_state.runs if r["label"] == selected)

        df = pd.read_csv(sel["csv"])
        st.success("íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! ì„ íƒí•œ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì•„ë˜ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")

        # âœ… ìƒìœ„ 1000í–‰ë§Œ í™”ë©´ì— í”„ë¦¬ë·°
        total_rows = len(df)
        st.caption(
            f"âš ï¸ ì•„ë˜ í‘œëŠ” ì´ {total_rows:,}í–‰ ì¤‘ "
            f"ìƒìœ„ {min(PREVIEW_N, total_rows):,}í–‰ë§Œ ë¯¸ë¦¬ë³´ê¸°ì…ë‹ˆë‹¤. "
            "ì „ì²´ëŠ” ì•„ë˜ì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”."
        )
        st.dataframe(df.head(PREVIEW_N), width="stretch")

        # ì‚¬ì´ë“œë°”ì— ì‹¤í–‰ ì‹œê°„ í‘œì‹œ
        st.sidebar.markdown("---")
        st.sidebar.subheader("ì‹¤í–‰ ì‹œê°„")
        st.sidebar.write(f" ì‹œì‘ {sel['start']}")
        st.sidebar.write(f" ì¢…ë£Œ {sel['end']}")
        st.sidebar.write(f" ì†Œìš” {sel['duration']}")

        # âœ… CSV ë‹¤ìš´ë¡œë“œ: ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ZIP
        csv_path = Path(sel["csv"])
        file_size_mb = csv_path.stat().st_size / (1024 * 1024)

        # html ê²½ë¡œ
        html_path = Path(sel["html"])

        col_csv, col_html = st.columns(2)
        with col_csv:
            if file_size_mb <= THRESHOLD_MB:
                st.download_button(
                    label=f"CSV Download ({file_size_mb:.1f} MB)",
                    data=csv_path.read_bytes(),
                    file_name=csv_path.name,
                    mime="text/csv",
                    width="stretch",
                )
            else:
                buf = BytesIO()
                with zipfile.ZipFile(buf, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
                    zf.writestr(csv_path.name, csv_path.read_bytes())
                zip_bytes = buf.getvalue()
                st.download_button(
                    label=f"CSV Download (ZIP, ì›ë³¸ {file_size_mb:.1f} MB)",
                    data=zip_bytes,
                    file_name=csv_path.stem + ".zip",
                    mime="application/zip",
                    width="stretch",
                )

        with col_html:
            # Degree ê¸°ë°˜ (í¬ê¸°=degree, ìƒ‰=eigenvector)
            deg_html = make_html_string_from_csv(str(csv_path), size_by="degree", color_by="degree")
            st.download_button(
                label="Visualization Download (Degree-based)",
                data=deg_html.encode("utf-8"),
                file_name=csv_path.stem + "_degree_network.html",
                mime="text/html",
                width="stretch",
            )

            # Eigenvector ê¸°ë°˜ (í¬ê¸°=eigenvector, ìƒ‰=degree)
            eig_html = make_html_string_from_csv(str(csv_path), size_by="eigenvector", color_by="eigenvector")
            st.download_button(
                label="Visualization Download (Eigenvector-based)",
                data=eig_html.encode("utf-8"),
                file_name=csv_path.stem + "_eigenvector_network.html",
                mime="text/html",
                width="stretch",
            )

            import json
            import pandas as pd

            def _safe_int(x):
                try: return int(x)
                except Exception: return None

            def load_metrics_if_any(csv_path: Path):
                """ìµœì¢… CSVê°€ ìˆëŠ” í´ë”ì— metrics.jsonì´ ìˆìœ¼ë©´ ì½ì–´ dictë¡œ ë°˜í™˜"""
                mfile = csv_path.parent / "metrics.json"
                if mfile.exists():
                    try:
                        return json.loads(mfile.read_text(encoding="utf-8"))
                    except Exception:
                        pass
                return {}

            def summarize_lightweight_from_csv(csv_path: Path):
                """metrics.jsonì´ ì—†ì„ ë•Œ CSVë§Œìœ¼ë¡œ ë…¸ë“œ/ì—£ì§€ ìˆ˜ ì§‘ê³„
                - ì—£ì§€ ë¦¬ìŠ¤íŠ¸(source/target) í˜•ì‹ ë˜ëŠ”
                - ë…¼ë¬¸ë³„ ê¸°ê´€ ë¦¬ìŠ¤íŠ¸(org_names) í˜•ì‹ ì§€ì›
                """
                import itertools, ast
                try:
                    df = pd.read_csv(csv_path)
                except Exception:
                    return {}

                cols = {c.lower(): c for c in df.columns}

                # 1) ì—£ì§€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ (source/target)
                src = cols.get("source") or cols.get("src")
                tgt = cols.get("target") or cols.get("dst")
                if src and tgt and (src in df.columns) and (tgt in df.columns):
                    node_count = pd.Index(
                        pd.concat([df[src], df[tgt]], ignore_index=True).dropna().unique()
                    ).size
                    edge_count = len(df)
                    return {"node_count": int(node_count), "edge_count": int(edge_count)}

                # 2) ë…¼ë¬¸ë³„ ê¸°ê´€ ë¦¬ìŠ¤íŠ¸(org_names)
                org_col = cols.get("org_names")
                if org_col and (org_col in df.columns):
                    def _safe_list(x):
                        if isinstance(x, list):
                            return x
                        if isinstance(x, str):
                            try:
                                v = ast.literal_eval(x)
                                if isinstance(v, (list, tuple)):
                                    return list(v)
                            except Exception:
                                pass
                            return [p.strip() for p in x.split(",") if p.strip()]
                        return []
                    org_lists = df[org_col].apply(_safe_list)

                    # ë…¸ë“œ ìˆ˜
                    nodes = {o.strip() for orgs in org_lists for o in orgs
                            if isinstance(o, str) and o and o.lower() != "none"}
                    node_count = len(nodes)

                    # ì—£ì§€ ìˆ˜
                    edge_count = 0
                    for orgs in org_lists:
                        uniq = list(dict.fromkeys([o.strip() for o in orgs
                                                if isinstance(o, str) and o and o.lower() != "none"]))
                        if len(uniq) >= 2:
                            pairs = {tuple(sorted(p)) for p in itertools.combinations(uniq, 2)}
                            edge_count += len(pairs)

                    return {"node_count": int(node_count), "edge_count": int(edge_count)}

                return {}
            
            def render_summary_table(metrics: dict):
                rows = [
                    ("ì´ ìˆ˜ì§‘ ë…¼ë¬¸ ìˆ˜",           metrics.get("total_papers")),
                    ("authorships ë¹„ì–´ìˆëŠ” ë…¼ë¬¸ ìˆ˜", metrics.get("authorships_empty")),
                    ("ì‚­ì œí•œ ë¬¸í—Œ ìˆ˜",            metrics.get("deleted_docs")),
                    ("DOI ê²°ì¸¡ ìˆ˜",              metrics.get("doi_missing")),
                    ("DOI ë³´ê°• ìˆ˜",              metrics.get("doi_filled")),
                    ("DOI ë³´ê°•ë¥ (%)",            metrics.get("doi_fill_rate")),
                    ("ROR ID ê²°ì¸¡ ìˆ˜",           metrics.get("ror_missing")),
                    ("ROR ID ë³´ê°• ìˆ˜",           metrics.get("ror_filled")),
                    ("ROR ID ë³´ê°•ë¥ (%)",         metrics.get("ror_fill_rate")),
                    ("ë…¸ë“œ ìˆ˜(ê¸°ê´€ ìˆ˜)",          metrics.get("node_count")),
                    ("ì—£ì§€ ìˆ˜(í˜‘ì—… ìˆ˜)",          metrics.get("edge_count")),
                ]
                df_show = pd.DataFrame(rows, columns=["ì§€í‘œ", "ê°’"])
                st.subheader("ğŸ“Š ìˆ˜ì§‘/ë³´ê°•/ë„¤íŠ¸ì›Œí¬ ìš”ì•½")
                st.dataframe(df_show, width="stretch")

            # metrics.json ìš°ì„ , ì—†ìœ¼ë©´ CSVë¡œ ê²½ëŸ‰ ì§‘ê³„
            _metrics = load_metrics_if_any(Path(csv_path))
            if not _metrics:
                _metrics = summarize_lightweight_from_csv(Path(csv_path))

            # ë³´ê°•ë¥  ê³„ì‚°(ìˆëŠ” ê²½ìš°ì—ë§Œ)
            for k_rate, (filled_key, missing_key) in {
                "doi_fill_rate": ("doi_filled", "doi_missing"),
                "ror_fill_rate": ("ror_filled", "ror_missing"),
            }.items():
                filled = _safe_int(_metrics.get(filled_key))
                missing = _safe_int(_metrics.get(missing_key))
                if filled is not None and missing not in (None, 0):
                    _metrics[k_rate] = round(100.0 * filled / missing, 2)

            render_summary_table(_metrics)

    else:
        if st.session_state.runs:
            options = [r["label"] for r in st.session_state.runs]
            selected = st.selectbox("ì‹¤í–‰ ê²°ê³¼ ì„ íƒ", options, index=len(options)-1)
            sel = next(r for r in st.session_state.runs if r["label"] == selected)

            # âœ… ì„ íƒëœ ì‹¤í–‰ì˜ ì‹œê°„ ë¡œê·¸ -> ì‚¬ì´ë“œë°”ì— í‘œì‹œ (ë“œë¡­ë‹¤ìš´ ë³€ê²½ ì‹œì—ë„ ìœ ì§€)
            st.sidebar.markdown("---")
            st.sidebar.subheader("ì‹¤í–‰ ì‹œê°„")
            st.sidebar.write(f" ì‹œì‘ {sel['start']}")
            st.sidebar.write(f" ì¢…ë£Œ {sel['end']}")
            st.sidebar.write(f" ì†Œìš” {sel['duration']}")

            df = pd.read_csv(sel["csv"])

            # âœ… ìƒìœ„ 1000í–‰ë§Œ í™”ë©´ì— í”„ë¦¬ë·°
            total_rows = len(df)
            st.caption(
                f"âš ï¸ ì•„ë˜ í‘œëŠ” ì´ {total_rows:,}í–‰ ì¤‘ "
                f"ìƒìœ„ {min(PREVIEW_N, total_rows):,}í–‰ë§Œ ë¯¸ë¦¬ë³´ê¸°ì…ë‹ˆë‹¤. "
                "ì „ì²´ëŠ” ì•„ë˜ì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”."
            )
            st.dataframe(df.head(PREVIEW_N), width="stretch")

            # âœ… CSV ë‹¤ìš´ë¡œë“œ: ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ZIP
            csv_path = Path(sel["csv"])
            file_size_mb = csv_path.stat().st_size / (1024 * 1024)
            html_path = Path(sel["html"])

            col_csv, col_html = st.columns(2)
            with col_csv:
                if file_size_mb <= THRESHOLD_MB:
                    st.download_button(
                        label=f"CSV Download ({file_size_mb:.1f} MB)",
                        data=csv_path.read_bytes(),
                        file_name=csv_path.name,
                        mime="text/csv",
                        width="stretch",
                    )
                else:
                    buf = BytesIO()
                    with zipfile.ZipFile(buf, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
                        zf.writestr(csv_path.name, csv_path.read_bytes())
                    zip_bytes = buf.getvalue()
                    st.download_button(
                        label=f"CSV Download (ZIP, ì›ë³¸ {file_size_mb:.1f} MB)",
                        data=zip_bytes,
                        file_name=csv_path.stem + ".zip",
                        mime="application/zip",
                        width="stretch",
                    )

            with col_html:
                #Degree ê¸°ë°˜
                deg_html = make_html_string_from_csv(str(csv_path), size_by="degree", color_by="eigenvector")
                st.download_button(
                    label="Visualization Download (Degree-based)",
                    data=deg_html.encode("utf-8"),
                    file_name=csv_path.stem + "_degree_network.html",
                    mime="text/html",
                    width="stretch",
                )

                #Eigenvector ê¸°ë°˜
                eig_html = make_html_string_from_csv(str(csv_path), size_by="eigenvector", color_by="degree")
                st.download_button(
                    label="Visualization Download (Eigenvector-based)",
                    data=eig_html.encode("utf-8"),
                    file_name=csv_path.stem + "_eigenvector_network.html",
                    mime="text/html",
                    width="stretch",
                )
        else:
            st.info("ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì • í›„ ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    app()
