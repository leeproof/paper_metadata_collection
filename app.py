import streamlit as st
import nest_asyncio
import pandas as pd
import datetime
from pathlib import Path

# ì´ë²¤íŠ¸ ë£¨í”„ ì¶©ëŒ ë°©ì§€ (async ì‚¬ìš© ì‹œ í•„ìˆ˜)
nest_asyncio.apply()

from new import run_pipeline

st.set_page_config(page_title="OpenAlex Paper Metadata Pipeline", layout="wide")

# ìºì‹œ ë°ì½”ë ˆì´í„° ì œê±° (íŒŒì¼ ìƒì„±/ì™¸ë¶€ I/OëŠ” ìºì‹œ ë¹„ê¶Œì¥)
def cached_run(issns, year_start, year_end, email):
    results = []
    step = 5  # 5ë…„ ë‹¨ìœ„ë¡œ ë¶„í•  ì‹¤í–‰
    for y0 in range(year_start, year_end+1, step):
        y1 = min(y0+step-1, year_end)
        csv_path, _ = run_pipeline(issns=issns, year_start=y0, year_end=y1, email=email)
        results.append(csv_path)

    # ê²°ê³¼ CSV í•©ì¹˜ê¸°
    df_all = pd.concat([pd.read_csv(f) for f in results], ignore_index=True)
    out_name = f"{'_'.join(issns)}_{year_start}_{year_end}_ror_extract_name.csv"
    df_all.to_csv(out_name, index=False, encoding="utf-8-sig")
    return out_name

def sidebar_controls():
    st.sidebar.header("ì„¤ì •")
    issns_text = st.sidebar.text_area(
        "ISSN ë¦¬ìŠ¤íŠ¸ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)",
        value="0043-1354\n0011-9164\n0733-9429",
        height=100,
    )
    issns = [s.strip() for s in issns_text.splitlines() if s.strip()]

    year_col1, year_col2 = st.sidebar.columns(2)
    year_start = year_col1.number_input("ì‹œì‘ ì—°ë„", value=2015, step=1)
    year_end = year_col2.number_input("ì¢…ë£Œ ì—°ë„", value=2024, step=1)

    email = st.sidebar.text_input("OpenAlex ì´ë©”ì¼", value="s0124kw@gmail.com")
    run_btn = st.sidebar.button("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰", use_container_width=True)
    return issns, int(year_start), int(year_end), email, run_btn

def app():
    st.title("Paper Metadata Collection Pipeline")

    issns, year_start, year_end, email, run_btn = sidebar_controls()

    if run_btn:

        # ì‹¤í–‰ ì‹œê°„ ê¸°ë¡
        start_time = datetime.datetime.now()

        with st.spinner("íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆì–´ìš”)"):
            final_csv = cached_run(issns,year_start,year_end,email)
        
        # ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
        end_time = datetime.datetime.now()
        duration = end_time - start_time

        df = pd.read_csv(final_csv)
        st.success("íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! ì•„ë˜ì—ì„œ íŒŒì¼ì„ ì„ íƒí•´ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
        st.dataframe(df, use_container_width=True)

        # ì‚¬ì´ë“œë°”ì— ì‹¤í–‰ ì‹œê°„ í‘œì‹œ
        st.sidebar.markdown("---")
        st.sidebar.subheader("ì‹¤í–‰ ì‹œê°„")
        st.sidebar.write(f" ì‹œì‘ {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        st.sidebar.write(f" ì¢…ë£Œ {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        st.sidebar.write(f" ì†Œìš” {duration}")


        # CSV ì§ë ¬í™”
        csv_bytes = df.to_csv(index=False, encoding="utf-8-sig")

        # ì„ íƒ CSV â†’ ì§ HTML íŒŒì¼ëª… ê³„ì‚°
        # ì˜ˆ: ABC.csv â†’ ABC_network.html
        html_candidate = final_csv.replace("_ror_extract_name.csv", "_ror_extract_name_network.html")
        html_path = Path(html_candidate)

        col_csv, col_html = st.columns(2)
        with col_csv:
            st.download_button(
                label="CSV Download",
                data=csv_bytes,
                file_name=Path(final_csv).name,
                mime="text/csv",
                use_container_width=True,
            )

        with col_html:
            if html_path.exists():
                html_bytes = html_path.read_bytes()
                st.download_button(
                    label="Visualization Download",
                    data=html_bytes,
                    file_name=html_path.name,
                    mime="text/html",
                    use_container_width=True,
                )
            else:
                st.warning("ì—°ê²°ëœ HTML íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í›„ ìƒì„±ë©ë‹ˆë‹¤)")
    else:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì • í›„ ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    app()
